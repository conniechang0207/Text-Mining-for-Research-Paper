{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>ans1547.txt</td>\n",
       "      <td>There are many possible reasons for coughing o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>ans307.txt</td>\n",
       "      <td>First generation antihistamines are considered...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>ans1627.txt</td>\n",
       "      <td>Though there is contraindication to taking the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>a24564.txt</td>\n",
       "      <td>Children should be at least 3 years old before...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>ans260.txt</td>\n",
       "      <td>Either a tendinitis or a bursitis of the hip m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>ans1148.txt</td>\n",
       "      <td>Thank you for your question. If you are lookin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>a7437.txt</td>\n",
       "      <td>The best diet is the one that works best for y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>a7336.txt</td>\n",
       "      <td>Gotta whear braces somtime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>a24768.txt</td>\n",
       "      <td>drink a lot(water)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a31641.txt</td>\n",
       "      <td>bcoz they dont hav enough time 2 spend wid the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>ans306.txt</td>\n",
       "      <td>Finpecia (finasteride) is a drug that is used ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>ans1290.txt</td>\n",
       "      <td>Thank you for your question. Your bout of food...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>ans1560.txt</td>\n",
       "      <td>There are two types of Herpes Virus : Herpesvi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ans1847.txt</td>\n",
       "      <td>Your symptoms may be due to Eustachian Tube Dy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>a24593.txt</td>\n",
       "      <td>It is possible, but unlikely.  Know a lady tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>ans789.txt</td>\n",
       "      <td>It is very difficult to comment whether there ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>a69495.txt</td>\n",
       "      <td>Close contact with the male genitals, even wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>ans806.txt</td>\n",
       "      <td>It seems unlikely that you may be pregnant tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  class\n",
       "1152  ans1547.txt  There are many possible reasons for coughing o...      1\n",
       "839    ans307.txt  First generation antihistamines are considered...      1\n",
       "1344  ans1627.txt  Though there is contraindication to taking the...      1\n",
       "732    a24564.txt  Children should be at least 3 years old before...      0\n",
       "584    ans260.txt  Either a tendinitis or a bursitis of the hip m...      1\n",
       "865   ans1148.txt  Thank you for your question. If you are lookin...      1\n",
       "1614    a7437.txt  The best diet is the one that works best for y...      0\n",
       "971     a7336.txt                        Gotta whear braces somtime       0\n",
       "1039   a24768.txt                                drink a lot(water)       0\n",
       "20     a31641.txt  bcoz they dont hav enough time 2 spend wid the...      0\n",
       "786    ans306.txt  Finpecia (finasteride) is a drug that is used ...      1\n",
       "1530  ans1290.txt  Thank you for your question. Your bout of food...      1\n",
       "477   ans1560.txt  There are two types of Herpes Virus : Herpesvi...      1\n",
       "95    ans1847.txt  Your symptoms may be due to Eustachian Tube Dy...      1\n",
       "1282   a24593.txt  It is possible, but unlikely.  Know a lady tha...      0\n",
       "273    ans789.txt  It is very difficult to comment whether there ...      1\n",
       "1035   a69495.txt  Close contact with the male genitals, even wit...      0\n",
       "1860   ans806.txt  It seems unlikely that you may be pregnant tak...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r', encoding='utf-8', errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfnonpro = data2df('HealthProNonPro/NonPro/', 0) # NEG\n",
    "dfpro = data2df('HealthProNonPro/Pro/', 1) # POS\n",
    "\n",
    "df = pd.concat([dfpro, dfnonpro], axis=0)\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1787, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpro.shape\n",
    "dfnonpro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1787, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnonpro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3661, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3661 entries, 0 to 1786\n",
      "Data columns (total 3 columns):\n",
      "file     3661 non-null object\n",
      "text     3661 non-null object\n",
      "class    3661 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 114.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data for Training/Testing. Use 20% for testing\n",
    "X, y = df['text'], df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    carotid artery disease be cause by the build u...\n",
       "1                                          baking soda\n",
       "2    of course -pron- could break otherwise how do ...\n",
       "3    the antibiotic should start show result in 24 ...\n",
       "4    -pron- could have the male equivalent of yeast...\n",
       "5    want to travel the entire world and will do -p...\n",
       "6    -pron- be call histoplasmosis -pron- condition...\n",
       "7     to find cure for all illness physical and mental\n",
       "8    honestly hon this be not -pron- fault why shou...\n",
       "9    speed be an amphetamine psychostimulant which ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Spacy to preprocess the data. Explore and pick appropriate preprocessing steps.\n",
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # clean up text\n",
    "    tokens = [token.lemma_.lower() # lemmatize and lower-case \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 #only preserve tokens that are 2 or more characters long\n",
    "                                    #token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve specific pos\n",
    "                                    #token.text in nlp.vocab and # check if token in vocab\n",
    "                                    #token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    #not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    #not token.is_space and # get rid of tokens that are spaces\n",
    "                                    #not token.is_stop # get rid of tokens that are stop words\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(list(Xtrain))\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtrain = pd.Series(clean_corpus)\n",
    "Xtrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     eat chicken soop\n",
       "1    thank -pron- for -pron- question now that -pro...\n",
       "2    tylenol be the safe pain medication -pron- can...\n",
       "3    try have and orgasm before have actual sex the...\n",
       "4    -pron- do not need sugar as part of -pron- dai...\n",
       "5    -pron- be difficult for -pron- to say whether ...\n",
       "6    the measure that would be helpful in relieve -...\n",
       "7    -pron- opinion yes that the good answer for th...\n",
       "8    thank -pron- for -pron- question any type of s...\n",
       "9                              not possible in week ..\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1 = nlp.pipe(list(Xtest))\n",
    "clean_corpus1 = [custom_tokenizer(doc) for doc in corpus1]\n",
    "Xtest = pd.Series(clean_corpus1)\n",
    "Xtest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1-Normalized Term Frequency\n",
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "transformer = Pipeline(steps = [('tv',TfidfVectorizer(binary=False, norm='l1', # tf - l1 norm\n",
    "                                                      use_idf=False, smooth_idf=False, # idf - none\n",
    "                                                      lowercase=True, stop_words='english', \n",
    "                                                      min_df=1, max_df=1.0, max_features=None, \n",
    "                                                      ngram_range=(1, 1))),\n",
    "                               ('nb',MultinomialNB(alpha=1.0, # laplace add-one smoothing\n",
    "                                                   fit_prior=True, # learn class prior-probabilities from data\n",
    "                                                   class_prior=None # none - go with whatever fit-prior says\n",
    "                                                  ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'tv__sublinear_tf': ['False', 'True'], # regularization penalty\n",
    "    'nb__alpha':[0.5,1.0,1.5,2.0,2.5,3.0] # simple imputer strategy\n",
    "}\n",
    "gscv = GridSearchCV(transformer, param_grid, cv=4, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tv', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l1', preprocessor=None, smooth_idf=False,\n",
       " ...alse,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'tv__sublinear_tf': ['False', 'True'], 'nb__alpha': [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931787175989086\n",
      "[[310  48]\n",
      " [  2 373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93       358\n",
      "           1       0.89      0.99      0.94       375\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       733\n",
      "   macro avg       0.94      0.93      0.93       733\n",
      "weighted avg       0.94      0.93      0.93       733\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict and evaluate combined preprocessing and model pipeline on test data\n",
    "# predict and evaluate best_estimator_ on test data\n",
    "\n",
    "\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931787175989086\n",
      "[[ 310 48 ]\n",
      " [ 2  373 ]]\n",
      "                precision             recall            f1-score\n",
      "\n",
      "              0.9935897435897436 0.8659217877094972 0.9253731343283582\n",
      "              0.8859857482185273 0.9946666666666667 0.9371859296482412\n"
     ]
    }
   ],
   "source": [
    "TN, FP, FN, TP = metrics.confusion_matrix(y_true=ytest, y_pred=ypred).ravel()\n",
    "precision0 = TN/(TN+FN)\n",
    "precision1 = TP/(FP+TP)\n",
    "recall0 = TN/(TN+FP)\n",
    "recall1 = TP/(FN+TP)\n",
    "flscore0 = 2*(precision0 * recall0) /(precision0 + recall0)\n",
    "flscore1 = 2*(precision1 * recall1) /(precision1 + recall1)\n",
    "\n",
    "print((TP + TN) / (TP + FP + FN + TN))\n",
    "print(\"[[\",TN,FP,\"]\\n\",\"[\",FN,\"\",TP,\"]]\")\n",
    "print(\"                precision             recall            f1-score\\n\")\n",
    "print(\"             \",precision0,recall0,flscore0)\n",
    "print(\"             \",precision1,recall1,flscore1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
